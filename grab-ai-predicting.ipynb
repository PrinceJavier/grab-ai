{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predicting\n",
    "by Prince Joseph Erneszer Javier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we evaluate the performance of our trained machine learning classifier on test data for Grab AI for SEA challenge under the Safety category. We were provided Telematics data and from these data we would develop models that can predict if a driver is driving safely or not. The raw features dataset contains 16 million samples and 11 columns including the `bookingID`. There are 20,000 unique `bookingID`'s each with either 0 or 1 corresponding to safe or unsafe driving. The data were preprocessed in `grab-ai-preprocessing-eda`. The models were trained in `grab-ai-training`. In this notebook, we developed a pipeline for processing and evaluating the performance of our trained models on test data that look like the raw data provided by Grab. Finally, `grab-ai-predicting` contains the pipeline for predicting on a new dataset.\n",
    "\n",
    "To improve the generalizeability of the predictions, the average predictions of the top 7 models were used. The predictions for both min-max scaling and standard scaling were also derived, giving a total of 14 predictions. The average prediction was used as the final prediction. The models for predicting are Gradient Boosting Machines, Nonlinear Support Vector Machines, Linear Support Vector Machines with L1 Norm, Linear Support Vector Machines with L2 Norm, and Neural Network. These were all trained in `grab-ai-training`.\n",
    "\n",
    "Using this ensemble of ML models, we got an accuracy of around 71%, which is higher than the proportional chance criterion (accuracy by random chance) of 62%. 75% of safe driving was predicted correctly, while 60% of unsafe driving was predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab AI for SEA challenge is a hackathon organized by Grab. Grab offers three challenges that can be solved using AI: Traffic Management, Computer Vision, and Safety. We tackle the Safety Challenge. The `Ride Safety` dataset was provided by Grab, which contains Telematics data (acceleration, gyroscope data, speed, etc.), `bookingID`, and labels (0 or 1 for safe or unsafe driving). The raw dataset was prepared in `grab-ai-preprocessing-eda`. The output of that notebook is used as input for machine learning classifier training. The models trained by `grab-ai-training` are evaluated on the 5% test set in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Ride Safety` dataset contains two folders: `features` and `labels`. `features` contains 10 CSV files which contain a total of 16 million telematics data samples. The columns in the `features` dataset as described in `data_dictionary.xlsx` are:\n",
    "\n",
    "|Column Name|Description|\n",
    "|:--|:--|\n",
    "|`bookingID`|trip id|\n",
    "|`Accuracy`|accuracy inferred by GPS in meters|\n",
    "|`Bearing`|GPS bearing|\n",
    "|`acceleration_x`|accelerometer reading in x axis (m/s2)|\n",
    "|`acceleration_y`|accelerometer reading in y axis (m/s2)|\n",
    "|`acceleration_z`|accelerometer reading in z axis (m/s2)|\n",
    "|`gyro_x`|gyroscope reading in x axis (rad/s)|\n",
    "|`gyro_y`|gyroscope reading in y axis (rad/s)|\n",
    "|`gyro_z`|gyroscope reading in z axis (rad/s)|\n",
    "|`second`|time of the record by number of seconds|\n",
    "|`Speed`|speed measured by GPS in m/s|\n",
    "\n",
    "In `grab-ai-preprocessing-eda`, the samples were aggregated and features were engineered. `bookingID` and `second` were not included as features. The following measures were calculated for each feature: min, max, range, mean, standard deviation, skewness, kurtosis, dominant frequency (from fourier transform periodogram), and maximum power (from fourier transform periodogram). An additional feature was added which is the trip length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import periodogram\n",
    "from collections import Counter\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths of features and labels\n",
    "path_feats =\"data/processed/df_test.csv\"\n",
    "path_labels = \"data/safety/labels/part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv\"\n",
    "\n",
    "df_feats = pd.read_csv(path_feats).drop_duplicates()\n",
    "df_labels = pd.read_csv(path_labels).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_f(y):\n",
    "    \"\"\"Given time series y, get frequency of maximum power\n",
    "    from periodogram\"\"\"\n",
    "    f, p = periodogram(y, scaling='spectrum')\n",
    "    ind = np.argsort(p)\n",
    "    f_max = f[ind[-1]]\n",
    "    return f_max\n",
    "\n",
    "def max_power(y):\n",
    "    \"\"\"Given time series y, get maximum power\"\"\"\n",
    "    f, p = periodogram(y, scaling='spectrum')\n",
    "    return p.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# we engineer feature, aggregating feature values per bookingID\n",
    "# getting min, max, range, mean, std, skewness, and kurtosis\n",
    "\n",
    "df_engg_feats = df_feats.drop(\"second\", axis=1)\n",
    "df_engg_feats = df_engg_feats.groupby(by=\"bookingID\", as_index=True).agg([np.min, np.max, np.ptp, np.mean, np.std, skew, kurtosis, dominant_f, max_power])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten column names\n",
    "cols = [df_engg_feats.columns[i][0]+\"_\"+df_engg_feats.columns[i][1] for i in range(len(df_engg_feats.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engg_feats.columns = cols\n",
    "df_engg_feats.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add length of each trip\n",
    "df_len = df_feats.groupby(by=\"bookingID\", as_index=True).agg(len).iloc[:, 0:1]\n",
    "df_len.columns = ['trip_len']\n",
    "df_len.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>Accuracy_amin</th>\n",
       "      <th>Accuracy_amax</th>\n",
       "      <th>Accuracy_ptp</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Accuracy_skew</th>\n",
       "      <th>Accuracy_kurtosis</th>\n",
       "      <th>Accuracy_dominant_f</th>\n",
       "      <th>Accuracy_max_power</th>\n",
       "      <th>...</th>\n",
       "      <th>Speed_amin</th>\n",
       "      <th>Speed_amax</th>\n",
       "      <th>Speed_ptp</th>\n",
       "      <th>Speed_mean</th>\n",
       "      <th>Speed_std</th>\n",
       "      <th>Speed_skew</th>\n",
       "      <th>Speed_kurtosis</th>\n",
       "      <th>Speed_dominant_f</th>\n",
       "      <th>Speed_max_power</th>\n",
       "      <th>trip_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.204</td>\n",
       "      <td>15.204</td>\n",
       "      <td>7.008253</td>\n",
       "      <td>3.153024</td>\n",
       "      <td>1.070632</td>\n",
       "      <td>0.602108</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>2.271603</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>19.270000</td>\n",
       "      <td>5.351266</td>\n",
       "      <td>5.661732</td>\n",
       "      <td>0.804261</td>\n",
       "      <td>-0.753928</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>12.302757</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1251.564</td>\n",
       "      <td>1248.564</td>\n",
       "      <td>11.157522</td>\n",
       "      <td>67.183017</td>\n",
       "      <td>15.394113</td>\n",
       "      <td>241.992297</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.380261</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>26.152094</td>\n",
       "      <td>27.152094</td>\n",
       "      <td>15.521918</td>\n",
       "      <td>9.096480</td>\n",
       "      <td>-0.561274</td>\n",
       "      <td>-1.259059</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.821424</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.100</td>\n",
       "      <td>2.100</td>\n",
       "      <td>3.537573</td>\n",
       "      <td>0.451916</td>\n",
       "      <td>-0.071964</td>\n",
       "      <td>-1.263237</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.057636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.625328</td>\n",
       "      <td>19.625328</td>\n",
       "      <td>6.496606</td>\n",
       "      <td>6.343458</td>\n",
       "      <td>0.435514</td>\n",
       "      <td>-1.305701</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>18.016253</td>\n",
       "      <td>1230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>3.198</td>\n",
       "      <td>5.800</td>\n",
       "      <td>2.602</td>\n",
       "      <td>5.223068</td>\n",
       "      <td>0.723952</td>\n",
       "      <td>-2.177536</td>\n",
       "      <td>2.978317</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.135486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.021782</td>\n",
       "      <td>26.021782</td>\n",
       "      <td>16.619441</td>\n",
       "      <td>8.364577</td>\n",
       "      <td>-0.920440</td>\n",
       "      <td>-0.561377</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>39.768221</td>\n",
       "      <td>1665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>3.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.763156</td>\n",
       "      <td>0.931148</td>\n",
       "      <td>2.333683</td>\n",
       "      <td>6.639845</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.197087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.478025</td>\n",
       "      <td>17.478025</td>\n",
       "      <td>4.900992</td>\n",
       "      <td>4.673188</td>\n",
       "      <td>0.838455</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>8.685996</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bookingID  Accuracy_amin  Accuracy_amax  Accuracy_ptp  Accuracy_mean  \\\n",
       "0          8          3.000         18.204        15.204       7.008253   \n",
       "1         13          3.000       1251.564      1248.564      11.157522   \n",
       "2         33          3.000          5.100         2.100       3.537573   \n",
       "3         35          3.198          5.800         2.602       5.223068   \n",
       "4         91          3.000          8.000         5.000       3.763156   \n",
       "\n",
       "   Accuracy_std  Accuracy_skew  Accuracy_kurtosis  Accuracy_dominant_f  \\\n",
       "0      3.153024       1.070632           0.602108             0.002584   \n",
       "1     67.183017      15.394113         241.992297             0.000814   \n",
       "2      0.451916      -0.071964          -1.263237             0.000813   \n",
       "3      0.723952      -2.177536           2.978317             0.000601   \n",
       "4      0.931148       2.333683           6.639845             0.022222   \n",
       "\n",
       "   Accuracy_max_power  ...  Speed_amin  Speed_amax  Speed_ptp  Speed_mean  \\\n",
       "0            2.271603  ...        -1.0   18.270000  19.270000    5.351266   \n",
       "1           58.380261  ...        -1.0   26.152094  27.152094   15.521918   \n",
       "2            0.057636  ...         0.0   19.625328  19.625328    6.496606   \n",
       "3            0.135486  ...         0.0   26.021782  26.021782   16.619441   \n",
       "4            0.197087  ...         0.0   17.478025  17.478025    4.900992   \n",
       "\n",
       "   Speed_std  Speed_skew  Speed_kurtosis  Speed_dominant_f  Speed_max_power  \\\n",
       "0   5.661732    0.804261       -0.753928          0.002584        12.302757   \n",
       "1   9.096480   -0.561274       -1.259059          0.000814        58.821424   \n",
       "2   6.343458    0.435514       -1.305701          0.000813        18.016253   \n",
       "3   8.364577   -0.920440       -0.561377          0.000601        39.768221   \n",
       "4   4.673188    0.838455       -0.097581          0.022222         8.685996   \n",
       "\n",
       "   trip_len  \n",
       "0     387.0  \n",
       "1    1228.0  \n",
       "2    1230.0  \n",
       "3    1665.0  \n",
       "4     180.0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge along bookingID\n",
    "df_engg_feats_2 = pd.merge(df_engg_feats, df_len, how=\"inner\", on=\"bookingID\")\n",
    "df_engg_feats_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>Accuracy_amin</th>\n",
       "      <th>Accuracy_amax</th>\n",
       "      <th>Accuracy_ptp</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Accuracy_skew</th>\n",
       "      <th>Accuracy_kurtosis</th>\n",
       "      <th>Accuracy_dominant_f</th>\n",
       "      <th>Accuracy_max_power</th>\n",
       "      <th>...</th>\n",
       "      <th>Speed_amax</th>\n",
       "      <th>Speed_ptp</th>\n",
       "      <th>Speed_mean</th>\n",
       "      <th>Speed_std</th>\n",
       "      <th>Speed_skew</th>\n",
       "      <th>Speed_kurtosis</th>\n",
       "      <th>Speed_dominant_f</th>\n",
       "      <th>Speed_max_power</th>\n",
       "      <th>trip_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.204</td>\n",
       "      <td>15.204</td>\n",
       "      <td>7.008253</td>\n",
       "      <td>3.153024</td>\n",
       "      <td>1.070632</td>\n",
       "      <td>0.602108</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>2.271603</td>\n",
       "      <td>...</td>\n",
       "      <td>18.270000</td>\n",
       "      <td>19.270000</td>\n",
       "      <td>5.351266</td>\n",
       "      <td>5.661732</td>\n",
       "      <td>0.804261</td>\n",
       "      <td>-0.753928</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>12.302757</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1251.564</td>\n",
       "      <td>1248.564</td>\n",
       "      <td>11.157522</td>\n",
       "      <td>67.183017</td>\n",
       "      <td>15.394113</td>\n",
       "      <td>241.992297</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.380261</td>\n",
       "      <td>...</td>\n",
       "      <td>26.152094</td>\n",
       "      <td>27.152094</td>\n",
       "      <td>15.521918</td>\n",
       "      <td>9.096480</td>\n",
       "      <td>-0.561274</td>\n",
       "      <td>-1.259059</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.821424</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1251.564</td>\n",
       "      <td>1248.564</td>\n",
       "      <td>11.157522</td>\n",
       "      <td>67.183017</td>\n",
       "      <td>15.394113</td>\n",
       "      <td>241.992297</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.380261</td>\n",
       "      <td>...</td>\n",
       "      <td>26.152094</td>\n",
       "      <td>27.152094</td>\n",
       "      <td>15.521918</td>\n",
       "      <td>9.096480</td>\n",
       "      <td>-0.561274</td>\n",
       "      <td>-1.259059</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>58.821424</td>\n",
       "      <td>1228.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>3.000</td>\n",
       "      <td>5.100</td>\n",
       "      <td>2.100</td>\n",
       "      <td>3.537573</td>\n",
       "      <td>0.451916</td>\n",
       "      <td>-0.071964</td>\n",
       "      <td>-1.263237</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.057636</td>\n",
       "      <td>...</td>\n",
       "      <td>19.625328</td>\n",
       "      <td>19.625328</td>\n",
       "      <td>6.496606</td>\n",
       "      <td>6.343458</td>\n",
       "      <td>0.435514</td>\n",
       "      <td>-1.305701</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>18.016253</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>3.198</td>\n",
       "      <td>5.800</td>\n",
       "      <td>2.602</td>\n",
       "      <td>5.223068</td>\n",
       "      <td>0.723952</td>\n",
       "      <td>-2.177536</td>\n",
       "      <td>2.978317</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.135486</td>\n",
       "      <td>...</td>\n",
       "      <td>26.021782</td>\n",
       "      <td>26.021782</td>\n",
       "      <td>16.619441</td>\n",
       "      <td>8.364577</td>\n",
       "      <td>-0.920440</td>\n",
       "      <td>-0.561377</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>39.768221</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bookingID  Accuracy_amin  Accuracy_amax  Accuracy_ptp  Accuracy_mean  \\\n",
       "0          8          3.000         18.204        15.204       7.008253   \n",
       "1         13          3.000       1251.564      1248.564      11.157522   \n",
       "2         13          3.000       1251.564      1248.564      11.157522   \n",
       "3         33          3.000          5.100         2.100       3.537573   \n",
       "4         35          3.198          5.800         2.602       5.223068   \n",
       "\n",
       "   Accuracy_std  Accuracy_skew  Accuracy_kurtosis  Accuracy_dominant_f  \\\n",
       "0      3.153024       1.070632           0.602108             0.002584   \n",
       "1     67.183017      15.394113         241.992297             0.000814   \n",
       "2     67.183017      15.394113         241.992297             0.000814   \n",
       "3      0.451916      -0.071964          -1.263237             0.000813   \n",
       "4      0.723952      -2.177536           2.978317             0.000601   \n",
       "\n",
       "   Accuracy_max_power  ...  Speed_amax  Speed_ptp  Speed_mean  Speed_std  \\\n",
       "0            2.271603  ...   18.270000  19.270000    5.351266   5.661732   \n",
       "1           58.380261  ...   26.152094  27.152094   15.521918   9.096480   \n",
       "2           58.380261  ...   26.152094  27.152094   15.521918   9.096480   \n",
       "3            0.057636  ...   19.625328  19.625328    6.496606   6.343458   \n",
       "4            0.135486  ...   26.021782  26.021782   16.619441   8.364577   \n",
       "\n",
       "   Speed_skew  Speed_kurtosis  Speed_dominant_f  Speed_max_power  trip_len  \\\n",
       "0    0.804261       -0.753928          0.002584        12.302757     387.0   \n",
       "1   -0.561274       -1.259059          0.000814        58.821424    1228.0   \n",
       "2   -0.561274       -1.259059          0.000814        58.821424    1228.0   \n",
       "3    0.435514       -1.305701          0.000813        18.016253    1230.0   \n",
       "4   -0.920440       -0.561377          0.000601        39.768221    1665.0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join with labels (aggregating and feature engineering)\n",
    "df_engg_feats_labels = pd.merge(df_engg_feats_2, df_labels, how=\"inner\", on=\"bookingID\")\n",
    "df_engg_feats_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 84)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_engg_feats_labels.drop_duplicates(subset=\"bookingID\", inplace=True)\n",
    "df_engg_feats_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature set\n",
    "X0 = df_engg_feats_2.drop([\"bookingID\"], axis=1)\n",
    "cols = X0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_engg_feats_labels.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 748, 1: 252})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0s and 1s\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.623008"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportional chance criterion\n",
    "state_counts = Counter(y)\n",
    "df_state = pd.DataFrame.from_dict(state_counts, orient='index')\n",
    "num = (df_state[0] / df_state[0].sum())**2\n",
    "pcc = num.sum()\n",
    "pcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of top models\n",
    "\n",
    "def predict(scaler=\"minmax\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given scaler name, scale dataset and predict using pretrained models\n",
    "    Uses all features\n",
    "    Return prediction as array of 0s and 1s from all models\n",
    "    \"\"\"\n",
    "\n",
    "    # scaling\n",
    "    path = f\"scalers/{scaler}.sav\"\n",
    "    sc = pickle.load(open(path, 'rb'))\n",
    "    \n",
    "    y_preds = []\n",
    "\n",
    "    # scale X\n",
    "    X = pd.DataFrame(sc.transform(X0))\n",
    "    X.columns = cols\n",
    "\n",
    "    model_names = [f\"models/{model}_{scaler}.sav\" for model in ['gbm', 'svc', 'linear_svc_l1', 'linear_svc_l2']]\n",
    "\n",
    "    for model_name in model_names:\n",
    "        # load the model from disk (machine learning)\n",
    "        filename = model_name\n",
    "        model = pickle.load(open(filename, 'rb'))\n",
    "        y_pred = model.predict(X)\n",
    "        print(accuracy_score(y, y_pred), model_name)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    # Deep learning\n",
    "    filename = f\"models/mlp_{scaler}_relu_adam_dropout-0.5_cols-82.hdf5\"\n",
    "    model = load_model(filename)\n",
    "    y_pred_2 = np.round(model.predict(X))\n",
    "    print(accuracy_score(y, y_pred_2), f\"nn_{scaler}\")\n",
    "    \n",
    "    y_preds.append(y_pred_2)\n",
    "    \n",
    "    return y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703 models/gbm_minmax.sav\n",
      "0.694 models/svc_minmax.sav\n",
      "0.674 models/linear_svc_l1_minmax.sav\n",
      "0.701 models/linear_svc_l2_minmax.sav\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0.724 nn_minmax\n",
      "0.701 models/gbm_std.sav\n",
      "0.675 models/svc_std.sav\n",
      "0.689 models/linear_svc_l1_std.sav\n",
      "0.693 models/linear_svc_l2_std.sav\n",
      "0.707 nn_std\n"
     ]
    }
   ],
   "source": [
    "y_pred_minmax = predict(\"minmax\")\n",
    "y_pred_std = predict(\"std\")\n",
    "\n",
    "# concatenate results from std and minmax models\n",
    "y_pred_all = y_pred_std + y_pred_minmax\n",
    "\n",
    "# get average of all values\n",
    "y_pred = np.round(np.array([np.array(i).flatten() for i in y_pred_all]).mean(axis=0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
